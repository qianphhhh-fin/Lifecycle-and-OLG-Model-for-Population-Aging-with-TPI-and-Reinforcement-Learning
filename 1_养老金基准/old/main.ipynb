{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理得到各变量的history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 394\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;66;03m# max_length = max(len(path) for path in consum)\u001b[39;00m\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;66;03m# consum_path_array = np.full((eval_episodes, max_length), np.nan)\u001b[39;00m\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;66;03m# for i, path in enumerate(consum):\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;66;03m# return life_summary_df\u001b[39;00m\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;66;03m# print(f\"模型{idx}评估完毕, 评估次数为{eval_episodes}\")\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    392\u001b[0m  \n\u001b[0;32m    393\u001b[0m     \u001b[38;5;66;03m# # 循环执行evaluate_model\u001b[39;00m\n\u001b[1;32m--> 394\u001b[0m     evaluate_model_dp(eval_episodes\u001b[38;5;241m=\u001b[39meval_episodes, eval_seed\u001b[38;5;241m=\u001b[39meval_seed)\n\u001b[0;32m    395\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m rl_model_name:\n\u001b[0;32m    396\u001b[0m         evaluate_model_rl(model_name, eval_episodes\u001b[38;5;241m=\u001b[39meval_episodes, eval_seed\u001b[38;5;241m=\u001b[39meval_seed)\n",
      "Cell \u001b[1;32mIn[2], line 79\u001b[0m, in \u001b[0;36mevaluate_model_dp\u001b[1;34m(eval_episodes, eval_seed)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_model_dp\u001b[39m(eval_episodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m, eval_seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3687851522\u001b[39m):\n\u001b[1;32m---> 79\u001b[0m     current_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;18m__file__\u001b[39m))\n\u001b[0;32m     80\u001b[0m     df_A \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(current_path,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult_cocco_matlab\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m),header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     81\u001b[0m     df_C \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(current_path,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult_cocco_matlab\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m),header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "from typing import Callable\n",
    "import json\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "# from stable_baselines3 import DDPG\n",
    "# from stable_baselines3 import TD3\n",
    "# from stable_baselines3 import PPO\n",
    "# from stable_baselines3 import SAC\n",
    "from sbx import DDPG, DQN, PPO, SAC, TD3, TQC, CrossQ\n",
    "from utils.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "from gymnasium.envs.registration import register\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "# get current directory of the current .ipynb \n",
    "cdir = os.path.abspath('.') # 获取当前目录\n",
    "pardir = os.path.abspath(os.path.join(os.getcwd(), \"../\")) # 获取上级目录\n",
    "dbdir = os.path.abspath(os.path.join(os.getcwd(), \"../..\")) # 获取上上级目录(为了读取美股数据库数据)\n",
    "\n",
    "# 将变量处理为终身路径\n",
    "def var_path(vars, eval_episodes, env):\n",
    "    max_length = max(len(path) for path in vars)\n",
    "    var_path_array = np.full((eval_episodes, max_length), np.nan)\n",
    "    for i, path in enumerate(vars):\n",
    "        var_path_array[i, :len(path)] = path\n",
    "    age_array = np.arange(env.get_attr('tb')[0], env.get_attr('tb')[0] + max_length)\n",
    "    full_var_path = np.column_stack((age_array, var_path_array.T))\n",
    "    var_path_df = pd.DataFrame(full_var_path,\n",
    "                                    columns=['年龄'] + [f'个体{i+1}' for i in range(eval_episodes)])\n",
    "    return var_path_df\n",
    "\n",
    "# import torch \n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import sys\n",
    "cdir = os.path.abspath('.') # 获取当前目录\n",
    "# print(sys.path)\n",
    "# 状态空间：现金余额，个人养老金账户余额，永久收入冲击，年龄\n",
    "register(\n",
    "    id='cocco-rl-norm',\n",
    "    entry_point='cocco_env_rl_norm:CoccoEnv',\n",
    ")\n",
    "register(\n",
    "    id='cocco-dp',\n",
    "    entry_point='cocco_env_dp:CoccoEnv',\n",
    ")\n",
    "log_dir = 'models//cocco_sac'\n",
    "\n",
    "eval_dir = 'eval//'\n",
    "# model_name = ['v13_pensionfund_penlim0_run7',\n",
    "#               'v13_pensionfund_penlim1p2_run15',\n",
    "#               'v13_pensionfund_nopenlim_run7'\n",
    "#               ]\n",
    "rl_model_name = [\n",
    "            #   'cocco-rl_cocco_run225//best_model_67', # 无随机死亡最佳\n",
    "            # 'cocco-rl_cocco_run231//best_model_67', # 有随机死亡最佳 \n",
    "            # 'cocco-rl_cocco_run248//best_model_567'\n",
    "            'cocco-rl-norm_cocco_run112//best_model',\n",
    "            # 'cocco-rl-norm_cocco_run11//best_model'\n",
    "              ]\n",
    "# model_name = [d for d in os.listdir(log_dir) if os.path.isdir(os.path.join(log_dir, d))]\n",
    "eval_episodes = 10000\n",
    "eval_seed =  3687851522\n",
    "# eval_seed = 1000\n",
    "params = {'distf': 0.95}\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model_dp(eval_episodes=10000, eval_seed=3687851522):\n",
    "\n",
    "    current_path = os.path.dirname(os.path.abspath(__file__))\n",
    "    df_A = pd.read_excel(os.path.join(current_path,'result_cocco_matlab','A.xlsx'),header=None)\n",
    "    df_C = pd.read_excel(os.path.join(current_path,'result_cocco_matlab','C.xlsx'),header=None) \n",
    "    df_V = pd.read_excel(os.path.join(current_path,'result_cocco_matlab','V.xlsx'),header=None)  \n",
    "    df_gcash = pd.read_excel(os.path.join(current_path,'result_cocco_matlab','gcash.xlsx'),header=None)\n",
    "    # 转换为numpy数组\n",
    "    A = df_A.to_numpy()\n",
    "    C = df_C.to_numpy()\n",
    "    V = df_V.to_numpy()\n",
    "    gcash = df_gcash.to_numpy().squeeze()\n",
    "\n",
    "    env = make_vec_env(\"cocco-dp\",seed=1, n_envs=1,  env_kwargs={'params': None})\n",
    "\n",
    "    action_set = []\n",
    "    score_history = []\n",
    "    age = []\n",
    "    income = []\n",
    "    consum = []\n",
    "    tmp_income = []\n",
    "    temp_consum = []\n",
    "    \n",
    "    reward_history = []\n",
    "\n",
    "    # from tqdm import tqdm\n",
    "    pbar = tqdm(total=eval_episodes, desc=f'dp模拟进度')    \n",
    "    for episode in range(eval_episodes):\n",
    "        pbar.update(1)\n",
    "        env.seed(seed=eval_seed+episode)\n",
    "        obs = env.reset()    \n",
    "        done = False\n",
    "        score = 0\n",
    "        episode_actions = np.empty((0,2))\n",
    "        temp_reward = []\n",
    "        while not done:\n",
    "            # 根据state[0]获取现金\n",
    "            cash = np.squeeze(obs[0][0])        \n",
    "            age_loc =  int(obs[0][1]) - env.get_attr('tb')[0] # 获取年龄\n",
    "\n",
    "            # 根据现金和年龄插值从A中获取action\n",
    "            action = np.array([np.interp(cash, gcash, C[:, age_loc]),np.interp(cash, gcash, A[:, age_loc])])\n",
    "            if age_loc == np.shape(C)[1]-1: # 如果到达最后一期,则固定消费比例为1（全部消费干净）\n",
    "                action[0] = cash\n",
    "            else:\n",
    "                action[0] = np.clip(action[0],0,cash)\n",
    "            # action[0] = action[0]/cash # 转换为消费比例\n",
    "            action[1] = np.clip(action[1],0,1)\n",
    "\n",
    "\n",
    "            obs, reward, done, info = env.step(np.array([action]))\n",
    "            score += reward * (params['distf'] ** len(episode_actions))\n",
    "            action[0] = action[0]/cash # 转换为消费比例\n",
    "            episode_actions = np.vstack((episode_actions, action))\n",
    "            temp_consum.append(info[0]['raw_consumption'])\n",
    "            temp_reward.append(reward[0])\n",
    "            # if info[0]['status']=='working':\n",
    "            tmp_income.append(info[0]['raw_income'])\n",
    "\n",
    "        age.append(info[0]['state'][1])\n",
    "        score_history.append(score[0])\n",
    "        action_set.append(episode_actions)\n",
    "        reward_history.append(temp_reward)\n",
    "        # norm_age = info[0]['state'][4]\n",
    "        # age.append(np.round((norm_age + 1) * (params['max_age'] - params['born_age']) / 2 + params['born_age'], 1) - 1)\n",
    "        \n",
    "\n",
    "        consum.append(temp_consum)\n",
    "        income.append(tmp_income)\n",
    "\n",
    "\n",
    "        tmp_income = []\n",
    "        temp_consum = []\n",
    "\n",
    "\n",
    "    life_path_detailed = pd.DataFrame({\n",
    "        '死亡年龄': age,\n",
    "        '工作期平均收入(万)': income,\n",
    "        '终身效用': score_history,\n",
    "    })\n",
    "    # 保存评估文件\n",
    "    # 从模型名中提取标识符（第二个_之后的字符串）\n",
    "    model_identifier = 'dp'\n",
    "\n",
    "    os.makedirs(eval_dir + model_identifier + '//', exist_ok=True)\n",
    "\n",
    "    # =====保存消费路径=====\n",
    "    consum_path_df = var_path(consum, eval_episodes, env)\n",
    "    consum_path_df.to_excel(eval_dir+ model_identifier + \"//\" + model_identifier + \"_consum_history.xlsx\", index=False)\n",
    "   # =====保存奖励历史=====\n",
    "    reward_history_df = var_path(reward_history, eval_episodes, env)\n",
    "    reward_history_df.to_excel(eval_dir+ model_identifier + \"//\" + model_identifier + \"_reward_history.xlsx\", index=False)\n",
    "    # 保存收入历史\n",
    "    income_history_df = var_path(income, eval_episodes, env)\n",
    "    income_history_df.to_excel(eval_dir+ model_identifier + \"//\" + model_identifier + \"_income_history.xlsx\", index=False)\n",
    "    # 保存风险资产比例决策历史\n",
    "    risky_pct = []\n",
    "    for episode in range(eval_episodes):\n",
    "        risky_pct.append(action_set[episode][:,1])\n",
    "    risky_pct_history_df = var_path(risky_pct, eval_episodes, env)\n",
    "    risky_pct_history_df.to_excel(eval_dir+ model_identifier + \"//\" + model_identifier + \"_risky_pct_history.xlsx\", index=False)\n",
    "\n",
    "        # 保存终身效用\n",
    "    utility_path = eval_dir + model_identifier + \"//\" + model_identifier + \"_score_history.xlsx\"\n",
    "    utility_path_df = pd.DataFrame(score_history, columns=['终身实现效用'])\n",
    "    utility_path_df.insert(0, 'agent', np.arange(1, eval_episodes+1)) # 增加第一列为agent\n",
    "    utility_path_df.to_excel(eval_dir+ model_identifier + \"//\" + model_identifier + \"_score_history.xlsx\", index=False)\n",
    "\n",
    "    life_summary = np.array([\n",
    "        np.mean(age),\n",
    "        np.mean(score_history),\n",
    "        np.std(score_history),\n",
    "    ])\n",
    "    life_summary_df = pd.DataFrame([life_summary], \n",
    "                                columns=[ '死亡年龄', '终身效用','终身效用标准差'])\n",
    "    print(model_identifier,': ',life_summary_df)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def evaluate_model_rl(idx, eval_episodes=1000, eval_seed=3687851522):\n",
    "    # # with open(os.path.join(log_dir, idx) +\"//params.json\", 'r') as file:\n",
    "    # #     params = json.load(file)\n",
    "    # current_path = os.path.dirname(os.path.abspath(__file__))    \n",
    "    # # env = make_vec_env(\"cocco-rl\",seed=1, n_envs=16, env_kwargs={'params': None})\n",
    "    # # env = VecNormalize.load(os.path.join(current_path, log_dir,idx) + \"//vec_env.pkl\", env)\n",
    "    # model = SAC.load(os.path.join(current_path, log_dir, idx), env=None) # , print_system_info=True\n",
    "\n",
    "    # env = make_vec_env(\"cocco-rl\",seed=eval_seed, n_envs=1, env_kwargs={'params': None})\n",
    "    # idx = idx.split('//')[0]\n",
    "    # env = VecNormalize.load(os.path.join(current_path, log_dir, idx) + \"//eval_env.pkl\",env)\n",
    "    # # env = make_vec_env(\"cocco-rl\",seed=eval_seed, n_envs=1, env_kwargs={'params':None},\\\n",
    "    # #                         monitor_kwargs={'discount_factor': params['distf']})         \n",
    "    # # env = VecNormalize(env, norm_obs=True, norm_reward=False)\n",
    "    # # model = DDPG.load(os.path.join(log_dir, idx) + \"//latest_model\", env)\n",
    "\n",
    "    current_path = os.path.dirname(os.path.abspath(__file__))     \n",
    "   \n",
    "    env = make_vec_env(\"cocco-rl-norm\",seed=1, n_envs=1, env_kwargs={'params': None})\n",
    "    env = VecNormalize.load(os.path.join(current_path, log_dir,idx.split('//')[0]) + \"//best_model_vec_env.pkl\", env)\n",
    "    model = SAC.load(os.path.join(current_path, log_dir, idx), env=env)\n",
    "\n",
    "    env = make_vec_env(\"cocco-rl-norm\",seed=eval_seed, n_envs=1, env_kwargs={'params':None},\\\n",
    "                            monitor_kwargs={'discount_factor':params['distf']})         \n",
    "    env = VecNormalize(env, norm_obs=False, norm_reward=False) # 评估不需要norm_obs\n",
    "\n",
    "\n",
    "    idx = idx.split('//')[0]\n",
    "    \n",
    "\n",
    "    action_set = []\n",
    "    score_history = []\n",
    "    age = []\n",
    "    income = []\n",
    "    consum = []\n",
    "    tmp_income = []\n",
    "    temp_consum = []\n",
    "    reward_history = []\n",
    "    # from tqdm import tqdm\n",
    "    pbar = tqdm(total=eval_episodes, desc=f'rl模拟进度')  \n",
    "    for episode in range(eval_episodes):  \n",
    "        pbar.update(1)\n",
    "        env.seed(seed=eval_seed+episode)\n",
    "        obs = env.reset()    \n",
    "        done = False\n",
    "        score = 0\n",
    "        episode_actions = np.empty((0,2))\n",
    "        temp_reward = []\n",
    "        while not done:\n",
    "            action, _states = model.predict(model.env.normalize_obs(obs), deterministic=True)\n",
    "            # 如果为最后一期，则固定消费比例为1（全部消费干净）\n",
    "            if len(episode_actions) == env.get_attr('tn')[0]-1:\n",
    "                action[0] = 1\n",
    "            # cash = env.unnormalize_obs(obs[0])[0] # 反归一化\n",
    "            obs, reward, done, info = env.step(action)               \n",
    "            # reward = -(((cash*action[0][0]))**(1-env.get_attr('gamma')[0]))*10 + 10       \n",
    "            score += reward * (params['distf'] ** len(episode_actions))\n",
    "            episode_actions = np.vstack((episode_actions, info[0]['real_actions']))\n",
    "            temp_consum.append(info[0]['消费'])\n",
    "            temp_reward.append(reward[0])\n",
    "            tmp_income.append(info[0]['raw_income'])\n",
    "        \n",
    "        score_history.append(score)\n",
    "        reward_history.append(temp_reward)\n",
    "        action_set.append(episode_actions)\n",
    "        # norm_age = info[0]['state'][4]\n",
    "        # age.append(np.round((norm_age + 1) * (params['max_age'] - params['born_age']) / 2 + params['born_age'], 1) - 1)\n",
    "        age.append(info[0]['state'][1])\n",
    "\n",
    "        consum.append(temp_consum)\n",
    "        income.append(tmp_income)\n",
    "\n",
    "\n",
    "        tmp_income = []\n",
    "        temp_consum = []\n",
    "\n",
    "\n",
    "    life_path_detailed = pd.DataFrame({\n",
    "        '死亡年龄': age,\n",
    "        '工作期平均收入(万)': income,\n",
    "        '终身效用': score_history,\n",
    "    })\n",
    "    # 保存评估文件\n",
    "    # 从模型名中提取标识符（第二个_之后的字符串）\n",
    "    model_identifier = 'rl_' +idx.split('_', 2)[2] \n",
    "\n",
    "    os.makedirs(eval_dir + model_identifier + '//', exist_ok=True)\n",
    "\n",
    "# =====保存消费路径=====\n",
    "    consum_path_df = var_path(consum, eval_episodes, env)\n",
    "    consum_path_df.to_excel(eval_dir+ model_identifier + \"//\" + model_identifier + \"_consum_history.xlsx\", index=False)\n",
    "    # 计算各个分位数\n",
    "    # consum_path_df = consum_path_df.iloc[:,]\n",
    "    # consum_stats = pd.DataFrame({\n",
    "    #     '均值': consum_path_df.mean(),\n",
    "    #     '0.1%': consum_path_df.quantile(0.001),\n",
    "    #     '1%': consum_path_df.quantile(0.01),\n",
    "    #     '5%': consum_path_df.quantile(0.05),\n",
    "    #     '10%': consum_path_df.quantile(0.1),\n",
    "    #     '25%': consum_path_df.quantile(0.25),\n",
    "    #     '50%': consum_path_df.quantile(0.5),\n",
    "    #     '75%': consum_path_df.quantile(0.75),\n",
    "    #     '90%': consum_path_df.quantile(0.9),\n",
    "    #     '95%': consum_path_df.quantile(0.95),\n",
    "    #     '99%': consum_path_df.quantile(0.99),\n",
    "    #     '99.9%': consum_path_df.quantile(0.999)\n",
    "    # })\n",
    "    # # 保存统计结果\n",
    "    # print(consum_stats)\n",
    "    \n",
    "   # =====保存奖励历史=====\n",
    "    reward_history_df = var_path(reward_history, eval_episodes, env)\n",
    "    reward_history_df.to_excel(eval_dir+ model_identifier + \"//\" + model_identifier + \"_reward_history.xlsx\", index=False)\n",
    "    # 保存收入历史\n",
    "    income_history_df = var_path(income, eval_episodes, env)\n",
    "    income_history_df.to_excel(eval_dir+ model_identifier + \"//\" + model_identifier + \"_income_history.xlsx\", index=False)\n",
    "    # 保存风险资产比例决策历史\n",
    "    risky_pct = []\n",
    "    for episode in range(eval_episodes):\n",
    "        risky_pct.append(action_set[episode][:,1])\n",
    "    risky_pct_history_df = var_path(risky_pct, eval_episodes, env)\n",
    "    risky_pct_history_df.to_excel(eval_dir+ model_identifier + \"//\" + model_identifier + \"_risky_pct_history.xlsx\", index=False)\n",
    "     # 保存终身效用\n",
    "    utility_path = eval_dir + model_identifier + \"//\" + model_identifier + \"_score_history.xlsx\"\n",
    "    utility_path_df = pd.DataFrame(score_history, columns=['终身实现效用'])\n",
    "    utility_path_df.insert(0, 'agent', np.arange(1, eval_episodes+1)) # 增加第一列为agent\n",
    "    utility_path_df.to_excel(eval_dir+ model_identifier + \"//\" + model_identifier + \"_score_history.xlsx\", index=False)\n",
    "    \n",
    "\n",
    "    # # =====保存生命总结=====\n",
    "    life_summary = np.array([\n",
    "        np.mean(age),\n",
    "        np.mean(score_history),\n",
    "        np.std(score_history),\n",
    "    ])\n",
    "    \n",
    "\n",
    "    life_summary_df = pd.DataFrame([life_summary], \n",
    "                                columns=[ '死亡年龄', '终身效用','终身效用标准差'])\n",
    "    print(idx,': ',life_summary_df)\n",
    " \n",
    "\n",
    "if __name__ == '__main__':\n",
    " \n",
    "    # # 循环执行evaluate_model\n",
    "    evaluate_model_dp(eval_episodes=eval_episodes, eval_seed=eval_seed)\n",
    "    for model_name in rl_model_name:\n",
    "        evaluate_model_rl(model_name, eval_episodes=eval_episodes, eval_seed=eval_seed)\n",
    "    # evaluate_model_rl(rl_model_name[0], eval_episodes=eval_episodes, eval_seed=eval_seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL优于DP样本的平均消费决策"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "import json\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import os\n",
    "# from stable_baselines3 import DDPG\n",
    "# from stable_baselines3 import TD3\n",
    "# from stable_baselines3 import PPO\n",
    "# from stable_baselines3 import SAC\n",
    "from sbx import DDPG, DQN, PPO, SAC, TD3, TQC, CrossQ\n",
    "from utils.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "from gymnasium.envs.registration import register\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "# get current directory of the current .ipynb \n",
    "cdir = os.path.abspath('.') # 获取当前目录\n",
    "pardir = os.path.abspath(os.path.join(os.getcwd(), \"../\")) # 获取上级目录\n",
    "dbdir = os.path.abspath(os.path.join(os.getcwd(), \"../..\")) # 获取上上级目录(为了读取美股数据库数据)\n",
    "\n",
    "# import torch \n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import sys\n",
    "cdir = os.path.abspath('.') # 获取当前目录\n",
    "# print(sys.path)\n",
    "# 状态空间：现金余额，个人养老金账户余额，永久收入冲击，年龄\n",
    "\n",
    "log_dir = 'models//cocco_sac'\n",
    "\n",
    "eval_dir = 'eval//'\n",
    "rl_model_name = [\n",
    "            #   'cocco-rl_cocco_run225//best_model_67', # 无随机死亡最佳\n",
    "            # 'cocco-rl_cocco_run231//best_model_67', # 有随机死亡最佳 \n",
    "            # 'cocco-rl_cocco_run242//best_model_618'\n",
    "            # 'cocco-rl-norm_cocco_run15//best_model',\n",
    "            'cocco-rl-norm_cocco_run16//best_model'\n",
    "              ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "        # 获取当前所在路径中\"博士论文\"所在目录\n",
    "    current_path = os.getcwd()\n",
    "    while os.path.basename(current_path) != \"博士论文\":\n",
    "        current_path = os.path.dirname(current_path)\n",
    "        if current_path == os.path.dirname(current_path):  # 已到达根目录仍未找到\n",
    "            raise Exception(\"未找到'博士论文'目录\")\n",
    "    thesis_dir = current_path + \"\\\\文字\\\\2-与传统方法比较\\\\fig\\\\\"\n",
    "\n",
    "    # =====读取dp和rl model的score_history======\n",
    "    utility_path = {}\n",
    "    model_identifier = 'rl_' + rl_model_name[0].split('_',2)[-1].split('//')[0]\n",
    "    rl_path = eval_dir + model_identifier + \"//\" + model_identifier + \"_score_history.xlsx\"\n",
    "    utility_path['RL'] = pd.read_excel(rl_path)\n",
    "    model_identifier = 'dp'\n",
    "    dp_path = eval_dir + model_identifier + \"//\" + model_identifier + \"_score_history.xlsx\"\n",
    "    utility_path['DP'] = pd.read_excel(dp_path)\n",
    "\n",
    "    # 找出RL中对应score比DP大的序号\n",
    "    rl_better_idx = utility_path['RL']['终身实现效用'] > utility_path['DP']['终身实现效用']\n",
    "    print(f\"RL表现优于DP的样本数: {rl_better_idx.sum()}\")\n",
    "    print(f\"RL表现优于DP的样本占比: {rl_better_idx.mean():.2%}\")\n",
    "\n",
    "    # =====读取dp和rl model的收入历史======\n",
    "    income_path = {}\n",
    "    model_identifier = 'rl_' + rl_model_name[0].split('_',2)[-1].split('//')[0]\n",
    "    rl_path = eval_dir + model_identifier + \"//\" + model_identifier + \"_income_history.xlsx\"\n",
    "    income_path['RL'] = pd.read_excel(rl_path)\n",
    "    rl_rl_better = np.mean(income_path['RL'].iloc[:,1:].iloc[:,rl_better_idx.values])\n",
    "    rl_dp_better = np.mean(income_path['RL'].iloc[:,1:].iloc[:,~rl_better_idx.values])\n",
    "\n",
    "\n",
    "    print([f'RL更好的路径收入:{rl_rl_better}, DP更好的路径收入: {rl_dp_better}'])\n",
    "    # =====读取dp和rl model的消费历史======\n",
    "    # consum_path = {}\n",
    "    # model_identifier = 'rl_' + rl_model_name[0].split('_',2)[-1].split('//')[0]\n",
    "    # rl_path = eval_dir + model_identifier + \"//\" + model_identifier + \"_consum_history.xlsx\"\n",
    "    # consum_path['RL'] = pd.read_excel(rl_path)\n",
    "    # consum_path['RL'] = pd.concat([consum_path['RL'].iloc[:,0], consum_path['RL'].iloc[:,1:].iloc[:,rl_better_idx.values]], axis=1)\n",
    "    # model_identifier = 'dp'\n",
    "    # dp_path = eval_dir + model_identifier + \"//\" + model_identifier + \"_consum_history.xlsx\"\n",
    "    # consum_path['DP'] = pd.read_excel(dp_path)\n",
    "    # consum_path['DP'] = pd.concat([consum_path['DP'].iloc[:,0], consum_path['DP'].iloc[:,1:].iloc[:,rl_better_idx.values]], axis=1)\n",
    "\n",
    "    # # 根据每个收入group画rl和dp的生涯消费决策与年龄的图\n",
    "    # plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签\n",
    "    # plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "    \n",
    "    # age_list = consum_path['RL'].iloc[:,0]\n",
    "    \n",
    "    # # 计算每个年龄点上的平均消费\n",
    "    # rl_mean = consum_path['RL'].iloc[:,1:].mean(axis=1,skipna=True)\n",
    "    # dp_mean = consum_path['DP'].iloc[:,1:].mean(axis=1,skipna=True) \n",
    "    \n",
    "    # plt.figure(figsize=(7,8))\n",
    "    # plt.plot(age_list, rl_mean, label='强化学习')\n",
    "    # plt.plot(age_list, dp_mean, label='动态规划')\n",
    "    # plt.title('RL优于DP样本的平均消费决策')\n",
    "    # plt.xlabel('年龄')\n",
    "    # plt.ylabel('消费')\n",
    "    # plt.legend()\n",
    "    # plt.grid(True)\n",
    "    # plt.tight_layout()\n",
    "    \n",
    "    # # 保存高清图到thesis_dir\n",
    "    # plt.savefig(thesis_dir + '//better_group_consumption.png', dpi=500, bbox_inches='tight')\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 每期score分布情况：确定reward怎么设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "import json\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import os\n",
    "# from stable_baselines3 import DDPG\n",
    "# from stable_baselines3 import TD3\n",
    "# from stable_baselines3 import PPO\n",
    "# from stable_baselines3 import SAC\n",
    "from sbx import DDPG, DQN, PPO, SAC, TD3, TQC, CrossQ\n",
    "from utils.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "from gymnasium.envs.registration import register\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "# get current directory of the current .ipynb \n",
    "cdir = os.path.abspath('.') # 获取当前目录\n",
    "pardir = os.path.abspath(os.path.join(os.getcwd(), \"../\")) # 获取上级目录\n",
    "dbdir = os.path.abspath(os.path.join(os.getcwd(), \"../..\")) # 获取上上级目录(为了读取美股数据库数据)\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签  \n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "# import torch \n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import sys\n",
    "cdir = os.path.abspath('.') # 获取当前目录\n",
    "# print(sys.path)\n",
    "# 状态空间：现金余额，个人养老金账户余额，永久收入冲击，年龄\n",
    "\n",
    "log_dir = 'models//cocco_sac'\n",
    "\n",
    "eval_dir = 'eval//'\n",
    "rl_model_name = [\n",
    "            #   'cocco-rl_cocco_run225//best_model_67', # 无随机死亡最佳\n",
    "            # 'cocco-rl_cocco_run231//best_model_67', # 有随机死亡最佳 \n",
    "            # 'cocco-rl_cocco_run242//best_model_618'\n",
    "            'cocco-rl-norm_cocco_run11//best_model'\n",
    "              ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "        # 获取当前所在路径中\"博士论文\"所在目录\n",
    "    current_path = os.getcwd()\n",
    "    while os.path.basename(current_path) != \"博士论文\":\n",
    "        current_path = os.path.dirname(current_path)\n",
    "        if current_path == os.path.dirname(current_path):  # 已到达根目录仍未找到\n",
    "            raise Exception(\"未找到'博士论文'目录\")\n",
    "    thesis_dir = current_path + \"\\\\文字\\\\2-与传统方法比较\\\\fig\\\\\"\n",
    "\n",
    "    # =====读取dp和rl model的score_history======\n",
    "    gamma = 3.84\n",
    "    utility_path = {}\n",
    "    income_path = {}\n",
    "    model_identifier = 'dp'\n",
    "    dp_path = eval_dir + model_identifier + \"//\" + model_identifier + \"_income_history.xlsx\"\n",
    "    income_path['DP'] = pd.read_excel(dp_path)\n",
    "\n",
    "    dp_path = eval_dir + model_identifier + \"//\" + model_identifier + \"_consum_history.xlsx\"\n",
    "    utility_path['DP'] = pd.read_excel(dp_path)\n",
    "    # utility_path['DP'].iloc[:,1:] = utility_path['DP'].iloc[:,1:]**(1-3.84)/(1-3.84)\n",
    "    \n",
    "\n",
    "    # temp[temp<-5] = -5\n",
    "\n",
    "\n",
    "    # 创建包含两个子图的图形\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "    # 子图1：绘制收入直方图\n",
    "    # 剔除nan值\n",
    "    temp = income_path['DP'].iloc[:,1:].values\n",
    "    temp = temp[~np.isnan(temp)]\n",
    "    ax1.hist(temp, bins=200, weights=np.ones(len(temp)) / len(temp), alpha=0.7, color='r', label='概率分布')\n",
    "    ax1.set_xlabel('收入值', fontsize=12)\n",
    "    ax1.set_ylabel('出现比例', fontsize=12)\n",
    "    ax1.set_title('动态规划模型收入的概率分布', fontsize=14)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend(fontsize=10)\n",
    "\n",
    "    \n",
    "    # 子图2：绘制消费直方图  \n",
    "    # 剔除nan值\n",
    "    temp = utility_path['DP'].iloc[:,1:].values\n",
    "    temp = temp[~np.isnan(temp)]\n",
    "    ax2.hist(temp, bins=200, weights=np.ones(len(temp)) / len(temp), alpha=0.7, color='r', label='概率分布')\n",
    "    ax2.set_xlabel('消费值', fontsize=12)\n",
    "    ax2.set_ylabel('出现比例', fontsize=12)\n",
    "    ax2.set_title('动态规划模型消费的概率分布', fontsize=14)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend(fontsize=10)\n",
    "\n",
    "    # 子图3：绘制效用直方图\n",
    "    utility_path['DP'].iloc[:,1:] = np.log(utility_path['DP'].iloc[:,1:]) # 需要调试的效用函数\n",
    "    temp = utility_path['DP'].iloc[:,1:].values\n",
    "    temp = temp[~np.isnan(temp)]\n",
    "    # temp = temp[temp>-3]\n",
    "    # temp[temp<-2]=-2\n",
    "    \n",
    "    ax3.hist(temp, bins=200, weights=np.ones(len(temp)) / len(temp), alpha=0.7, color='b', label='概率分布')\n",
    "    ax3.set_xlabel('效用值', fontsize=12)\n",
    "    ax3.set_ylabel('出现比例', fontsize=12)\n",
    "    ax3.set_title('动态规划模型效用的概率分布', fontsize=14)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.legend(fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各收入段消费情况比较\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "import json\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import os\n",
    "# from stable_baselines3 import DDPG\n",
    "# from stable_baselines3 import TD3\n",
    "# from stable_baselines3 import PPO\n",
    "# from stable_baselines3 import SAC\n",
    "from sbx import DDPG, DQN, PPO, SAC, TD3, TQC, CrossQ\n",
    "from utils.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "from gymnasium.envs.registration import register\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "# get current directory of the current .ipynb \n",
    "cdir = os.path.abspath('.') # 获取当前目录\n",
    "pardir = os.path.abspath(os.path.join(os.getcwd(), \"../\")) # 获取上级目录\n",
    "dbdir = os.path.abspath(os.path.join(os.getcwd(), \"../..\")) # 获取上上级目录(为了读取美股数据库数据)\n",
    "\n",
    "# import torch \n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import sys\n",
    "cdir = os.path.abspath('.') # 获取当前目录\n",
    "# print(sys.path)\n",
    "# 状态空间：现金余额，个人养老金账户余额，永久收入冲击，年龄\n",
    "log_dir = 'models//cocco_sac'\n",
    "\n",
    "eval_dir = 'eval//'\n",
    "# model_name = ['v13_pensionfund_penlim0_run7',\n",
    "#               'v13_pensionfund_penlim1p2_run15',\n",
    "#               'v13_pensionfund_nopenlim_run7'\n",
    "#               ]\n",
    "rl_model_name = [\n",
    "            #   'cocco-rl_cocco_run225//best_model_67', # 无随机死亡最佳\n",
    "            #   'cocco-rl_cocco_run229//best_model_68',\n",
    "            #   'cocco-rl_cocco_run230//best_model_63', # 有随机死亡最佳 \n",
    "            # 'cocco-rl_cocco_run231//best_model_67', # 有随机死亡最佳 \n",
    "            # 'cocco-rl_cocco_run233//best_model_141', # 有随机死亡最佳 \n",
    "            # 'cocco-rl_cocco_run239//best_model_613',\n",
    "            # 'cocco-rl_cocco_run240//best_model_418',\n",
    "            # 'cocco-rl_cocco_run241//best_model_526',\n",
    "            'cocco-rl-norm_cocco_run7//best_model'\n",
    "            # 'cocco-rl_cocco_run234//best_model_131',\n",
    "              ]\n",
    "# model_name = [d for d in os.listdir(log_dir) if os.path.isdir(os.path.join(log_dir, d))]\n",
    "eval_episodes = 1000\n",
    "eval_seed =  3687851522\n",
    "# eval_seed = 1000\n",
    "params = {'distf': 0.95}\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # 获取当前所在路径中\"博士论文\"所在目录\n",
    "    current_path = os.getcwd()\n",
    "    while os.path.basename(current_path) != \"博士论文\":\n",
    "        current_path = os.path.dirname(current_path)\n",
    "        if current_path == os.path.dirname(current_path):  # 已到达根目录仍未找到\n",
    "            raise Exception(\"未找到'博士论文'目录\")\n",
    "    thesis_dir = current_path + \"\\\\文字\\\\2-与传统方法比较\\\\fig\\\\\"\n",
    "    \n",
    "\n",
    "    # =====读取dp和rl model的score_history======\n",
    "    consum_path = {}\n",
    "    model_identifier = 'rl_' + rl_model_name[0].split('_',2)[-1].split('//')[0]\n",
    "    rl_path = eval_dir + model_identifier + \"//\" + model_identifier + \"_consum_history.xlsx\"\n",
    "    consum_path['RL'] = pd.read_excel(rl_path)\n",
    "    model_identifier = 'dp'\n",
    "    dp_path = eval_dir + model_identifier + \"//\" + model_identifier + \"_consum_history.xlsx\"\n",
    "    consum_path['DP'] = pd.read_excel(dp_path)\n",
    "\n",
    "    # =====读取dp model的income_history(与rl相同)======\n",
    "    model_identifier = 'rl_' + rl_model_name[0].split('_',2)[-1].split('//')[0]\n",
    "    rl_path = eval_dir + model_identifier + \"//\" + model_identifier + \"_income_history.xlsx\"\n",
    "    income_path = pd.read_excel(rl_path)\n",
    "    mean_income = income_path.iloc[:, 1:].mean(axis=0, skipna=True)\n",
    "    # 获取收入分别处于0-10%、10-25%、25-50%、50-75%、75-90%，90-100%分位数的agent loc\n",
    "    percentiles = [0, 10, 25, 50, 75, 90, 100]\n",
    "    income_percentiles = np.percentile(mean_income, percentiles)\n",
    "    income_groups = {}\n",
    "    for i in range(len(percentiles)-1):\n",
    "        if i == len(percentiles)-2:\n",
    "            mask = mean_income >= income_percentiles[i]\n",
    "        else:\n",
    "            mask = (mean_income >= income_percentiles[i]) & (mean_income < income_percentiles[i+1])\n",
    "        income_groups[f'{percentiles[i]}-{percentiles[i+1]}'] = np.where(mask)[0]\n",
    "    # 根据以上loc,获取utility_path中对应loc的终身效用\n",
    "\n",
    "    # 根据每个收入group画rl和dp的生涯消费决策与年龄的图,每个收入group一个子图\n",
    "    # 添加画图的中文支持\n",
    "    plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签\n",
    "    \n",
    "    plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "    idx = 0\n",
    "    age_list = consum_path['RL'].iloc[:,0]\n",
    "    plt.figure(figsize=(7,8))\n",
    "    subplot_num = len(income_groups)\n",
    "    row = (subplot_num + 1) // 2  # 向上取整\n",
    "    col = 2\n",
    "    for i, (group, loc) in enumerate(income_groups.items(), 1):\n",
    "        plt.subplot(row, col, i)\n",
    "        for model in ['RL', 'DP']:\n",
    "            temp = consum_path[model].iloc[:,loc+1].mean(axis=1)\n",
    "            plt.plot(age_list, temp, label=model)\n",
    "        plt.title(f'收入分位: {group}%')\n",
    "        plt.xlabel('年龄')\n",
    "        plt.ylabel('消费')\n",
    "        plt.legend()\n",
    "    plt.tight_layout()\n",
    "    # 保存高清图到thesis_dir\n",
    "    plt.savefig(thesis_dir + '//income_group_consumption.png', dpi=500, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各收入阶段agent已实现平均效用比较\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{>{\\centering\\arraybackslash}m{2cm}>{\\centering\\arraybackslash}m{3cm}>{\\centering\\arraybackslash}m{2cm}>{\\centering\\arraybackslash}m{2cm}>{\\centering\\arraybackslash}m{2cm}>{\\centering\\arraybackslash}m{2cm}>{\\centering\\arraybackslash}m{2cm}>{\\centering\\arraybackslash}m{2cm}}\n",
      "\\toprule\n",
      "模型 & 收入分位(\\%) & Mean & Std. & Median & Max & Min & Obs. \\\\\n",
      "\\midrule\n",
      "RL & 0-10 & -18.993 & 6.161 & -17.568 & -9.208 & -45.462 & 1000 \\\\\n",
      "RL & 10-25 & -8.932 & 2.321 & -8.530 & -4.170 & -26.019 & 1500 \\\\\n",
      "RL & 25-50 & -4.822 & 1.451 & -4.595 & -0.339 & -18.917 & 2500 \\\\\n",
      "RL & 50-75 & -2.790 & 0.952 & -2.625 & -0.147 & -8.838 & 2500 \\\\\n",
      "RL & 75-90 & -1.900 & 0.745 & -1.742 & -0.613 & -6.747 & 1500 \\\\\n",
      "RL & 90-100 & -1.263 & 0.561 & -1.151 & -0.248 & -4.952 & 1000 \\\\\n",
      "RL & all & -5.553 & 5.579 & -3.596 & -0.147 & -45.462 & 10000 \\\\\n",
      "DP & 0-10 & -21.541 & 8.818 & -19.447 & -4.907 & -64.550 & 1000 \\\\\n",
      "DP & 10-25 & -8.972 & 2.758 & -8.525 & -3.140 & -28.887 & 1500 \\\\\n",
      "DP & 25-50 & -4.686 & 1.515 & -4.411 & -0.415 & -18.982 & 2500 \\\\\n",
      "DP & 50-75 & -2.694 & 0.967 & -2.530 & -0.135 & -8.659 & 2500 \\\\\n",
      "DP & 75-90 & -1.858 & 0.751 & -1.703 & -0.609 & -6.576 & 1500 \\\\\n",
      "DP & 90-100 & -1.264 & 0.562 & -1.159 & -0.280 & -5.148 & 1000 \\\\\n",
      "DP & all & -5.750 & 6.575 & -3.445 & -0.135 & -64.550 & 10000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable\n",
    "import json\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import os\n",
    "# from stable_baselines3 import DDPG\n",
    "# from stable_baselines3 import TD3\n",
    "# from stable_baselines3 import PPO\n",
    "# from stable_baselines3 import SAC\n",
    "from sbx import DDPG, DQN, PPO, SAC, TD3, TQC, CrossQ\n",
    "from utils.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "from gymnasium.envs.registration import register\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "# get current directory of the current .ipynb \n",
    "cdir = os.path.abspath('.') # 获取当前目录\n",
    "pardir = os.path.abspath(os.path.join(os.getcwd(), \"../\")) # 获取上级目录\n",
    "dbdir = os.path.abspath(os.path.join(os.getcwd(), \"../..\")) # 获取上上级目录(为了读取美股数据库数据)\n",
    "\n",
    "# import torch \n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import sys\n",
    "cdir = os.path.abspath('.') # 获取当前目录\n",
    "# print(sys.path)\n",
    "# 状态空间：现金余额，个人养老金账户余额，永久收入冲击，年龄\n",
    "\n",
    "log_dir = 'models//cocco_sac'\n",
    "\n",
    "eval_dir = 'eval//'\n",
    "rl_model_name = [\n",
    "            #   'cocco-rl_cocco_run225//best_model_67', # 无随机死亡最佳\n",
    "            # 'cocco-rl_cocco_run231//best_model_67', # 有随机死亡最佳 \n",
    "            # 'cocco-rl_cocco_run242//best_model_618'\n",
    "            'cocco-rl-norm_cocco_run21//best_model'\n",
    "              ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "\n",
    "    # =====读取dp和rl model的score_history======\n",
    "    utility_path = {}\n",
    "    model_identifier = 'rl_' + rl_model_name[0].split('_',2)[-1].split('//')[0]\n",
    "    rl_path = eval_dir + model_identifier + \"//\" + model_identifier + \"_score_history.xlsx\"\n",
    "    utility_path['RL'] = pd.read_excel(rl_path)\n",
    "    model_identifier = 'dp'\n",
    "    dp_path = eval_dir + model_identifier + \"//\" + model_identifier + \"_score_history.xlsx\"\n",
    "    utility_path['DP'] = pd.read_excel(dp_path)\n",
    "\n",
    "    # =====读取dp model的income_history(与rl相同)======\n",
    "    model_identifier = 'rl_' + rl_model_name[0].split('_',2)[-1].split('//')[0]\n",
    "    rl_path = eval_dir + model_identifier + \"//\" + model_identifier + \"_income_history.xlsx\"\n",
    "    income_path = pd.read_excel(rl_path)\n",
    "    mean_income = income_path.iloc[:, 1:].mean(axis=0, skipna=True)\n",
    "    # 获取收入分别处于0-10%、10-25%、25-50%、50-75%、75-90%，90-100%分位数的agent loc\n",
    "    percentiles = [0, 10, 25, 50, 75, 90, 100]\n",
    "    income_percentiles = np.percentile(mean_income, percentiles)\n",
    "    income_groups = {}\n",
    "    for i in range(len(percentiles)-1):\n",
    "        if i == len(percentiles)-2:\n",
    "            mask = mean_income >= income_percentiles[i]\n",
    "        else:\n",
    "            mask = (mean_income >= income_percentiles[i]) & (mean_income < income_percentiles[i+1])\n",
    "        income_groups[f'{percentiles[i]}-{percentiles[i+1]}'] = np.where(mask)[0]\n",
    "    # 根据以上loc,获取utility_path中对应loc的终身效用\n",
    "    mean_utility = pd.DataFrame(columns=['模型', '收入分位(\\%)', 'Mean','Std.','Median','Max','Min','Obs.'])\n",
    "    idx = 0\n",
    "    for model in ['RL', 'DP']:\n",
    "        for group, loc in income_groups.items():\n",
    "            temp = utility_path[model].iloc[loc, 1]\n",
    "            income_mean = mean_income[loc].mean()  # 计算该收入分位的平均收入\n",
    "            mean_utility.loc[idx,['模型', '收入分位(\\%)',  'Mean','Std.','Median','Max','Min','Obs.']] = \\\n",
    "            [model, group,  temp.mean(), temp.std(), temp.median(), temp.max(), temp.min(), len(temp)]\n",
    "            idx += 1\n",
    "        temp = utility_path[model].iloc[:, 1]\n",
    "        income_mean = mean_income.mean()  # 计算总体的平均收入\n",
    "        mean_utility.loc[idx,['模型', '收入分位(\\%)',  'Mean','Std.','Median','Max','Min','Obs.']] = \\\n",
    "            [model, 'all', temp.mean(), temp.std(), temp.median(), temp.max(), temp.min(), len(temp)]\n",
    "        idx += 1\n",
    "\n",
    "\n",
    "    # 输出为tex格式，保留小数点后两位\n",
    "    f = mean_utility.to_latex(index=False, float_format='%.3f')\n",
    "    # 将{lll...}替换为{>{\\centering\\arraybackslash}m{1cm}>{\\centering\\arraybackslash}m{3cm}*{列数-1}{>{\\centering\\arraybackslash}m{2cm}}},注意\n",
    "    # 获取列数\n",
    "    num_cols = len(mean_utility.columns)\n",
    "    # 生成对应数量的列格式\n",
    "    col_format = '{' + '>{\\centering\\\\arraybackslash}m{2cm}' + '>{\\centering\\\\arraybackslash}m{3cm}' + \\\n",
    "                 ''.join(['>{\\centering\\\\arraybackslash}m{2cm}' for _ in range(num_cols-2)]) + '}'\n",
    "    # 替换原有的列格式\n",
    "    f = f.replace('{' + 'l'*num_cols + '}', col_format)\n",
    "    print(f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 根据收入确定收入缩放比例（用于养老模型计算税收）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "import json\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import os\n",
    "# from stable_baselines3 import DDPG\n",
    "# from stable_baselines3 import TD3\n",
    "# from stable_baselines3 import PPO\n",
    "# from stable_baselines3 import SAC\n",
    "from sbx import DDPG, DQN, PPO, SAC, TD3, TQC, CrossQ\n",
    "from utils.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "from gymnasium.envs.registration import register\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "# get current directory of the current .ipynb \n",
    "cdir = os.path.abspath('.') # 获取当前目录\n",
    "pardir = os.path.abspath(os.path.join(os.getcwd(), \"../\")) # 获取上级目录\n",
    "dbdir = os.path.abspath(os.path.join(os.getcwd(), \"../..\")) # 获取上上级目录(为了读取美股数据库数据)\n",
    "\n",
    "# import torch \n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import sys\n",
    "cdir = os.path.abspath('.') # 获取当前目录\n",
    "# print(sys.path)\n",
    "# 状态空间：现金余额，个人养老金账户余额，永久收入冲击，年龄\n",
    "log_dir = 'models//cocco_sac'\n",
    "\n",
    "eval_dir = 'eval//'\n",
    "# model_name = ['v13_pensionfund_penlim0_run7',\n",
    "#               'v13_pensionfund_penlim1p2_run15',\n",
    "#               'v13_pensionfund_nopenlim_run7'\n",
    "#               ]\n",
    "rl_model_name = [\n",
    "            #   'cocco-rl_cocco_run225//best_model_67', # 无随机死亡最佳\n",
    "            #   'cocco-rl_cocco_run229//best_model_68',\n",
    "            #   'cocco-rl_cocco_run230//best_model_63', # 有随机死亡最佳 \n",
    "            # 'cocco-rl_cocco_run231//best_model_67', # 有随机死亡最佳 \n",
    "            # 'cocco-rl_cocco_run233//best_model_141', # 有随机死亡最佳 \n",
    "            # 'cocco-rl_cocco_run239//best_model_613',\n",
    "            # 'cocco-rl_cocco_run240//best_model_418',\n",
    "            # 'cocco-rl_cocco_run241//best_model_526',\n",
    "            'cocco-rl-norm_cocco_run7//best_model'\n",
    "            # 'cocco-rl_cocco_run234//best_model_131',\n",
    "              ]\n",
    "# model_name = [d for d in os.listdir(log_dir) if os.path.isdir(os.path.join(log_dir, d))]\n",
    "eval_episodes = 1000\n",
    "eval_seed =  3687851522\n",
    "# eval_seed = 1000\n",
    "params = {'distf': 0.95}\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "\n",
    "    # =====读取dp和rl model的score_history======\n",
    "    income_path = {}\n",
    "    model_identifier = 'dp'\n",
    "    dp_path = eval_dir + model_identifier + \"//\" + model_identifier + \"_income_history.xlsx\"\n",
    "    income_path['DP'] = pd.read_excel(dp_path)\n",
    "\n",
    "    # 计算20-60岁平均收入\n",
    "    age_range = range(20, 61)  # 20-60岁\n",
    "    dp_income = income_path['DP']\n",
    "    \n",
    "    # 筛选20-60岁数据\n",
    "    dp_income_filtered = dp_income[dp_income['年龄'].isin(age_range)]\n",
    "    \n",
    "    # 计算平均收入\n",
    "    temp = dp_income_filtered.iloc[:,1:].copy()\n",
    "    scale = 6.87478\n",
    "    scaled_temp = np.exp(np.log(temp)*scale)\n",
    "    print(f\"DP模型20-60岁收入缩放比例: {scale:.6f}\")\n",
    "    print(f\"DP模型20-60岁平均收入: {np.mean(scaled_temp):.6f}万元\")\n",
    "    print(f\"DP模型20-60岁最低收入: {np.min(scaled_temp):.6f}万元\")\n",
    "    print(f\"DP模型20-60岁最高收入: {np.max(scaled_temp):.6f}万元\")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
