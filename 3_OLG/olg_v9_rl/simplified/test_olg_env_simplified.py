"""
æµ‹è¯•OLGEnvV9SACSimplifiedç¯å¢ƒ

ğŸ¯ ç›®æ ‡ï¼š
- ä½¿ç”¨éšæœºå†³ç­–æµ‹è¯•ç¯å¢ƒçš„åŸºæœ¬åŠŸèƒ½
- æ£€æŸ¥çŠ¶æ€è½¬ç§»æ˜¯å¦æ­£å¸¸
- éªŒè¯æ•ˆç”¨è®¡ç®—æ˜¯å¦åˆç†
- è§‚å¯Ÿç”Ÿå‘½å‘¨æœŸè·¯å¾„æ˜¯å¦ç¬¦åˆé¢„æœŸ
"""

import os
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'

import numpy as np
import matplotlib.pyplot as plt
import sys
import time
from typing import Dict, List, Tuple

import matplotlib
import matplotlib.font_manager as fm
# é…ç½®matplotlibä¸­æ–‡å­—ä½“æ”¯æŒ
def setup_chinese_fonts():
    """è®¾ç½®matplotlibä¸­æ–‡å­—ä½“"""
    chinese_fonts = ['SimHei', 'Microsoft YaHei', 'WenQuanYi Micro Hei', 'DejaVu Sans']
    available_fonts = [f.name for f in fm.fontManager.ttflist]
    
    for font in chinese_fonts:
        if font in available_fonts:
            matplotlib.rcParams['font.sans-serif'] = [font] + matplotlib.rcParams['font.sans-serif']
            print(f"âœ… ä½¿ç”¨ä¸­æ–‡å­—ä½“: {font}")
            break
    else:
        print("âš ï¸ æœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œå¯èƒ½æ˜¾ç¤ºä¸ºæ–¹æ¡†")
        matplotlib.rcParams['font.sans-serif'] = ['DejaVu Sans']
    
    matplotlib.rcParams['axes.unicode_minus'] = False  # æ­£ç¡®æ˜¾ç¤ºè´Ÿå·

# åˆå§‹åŒ–ä¸­æ–‡å­—ä½“
setup_chinese_fonts()

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from main_olg_v9_utils import OLG_V9_Utils
from simplified.main_olg_v9_utils_simplified import OLGUtilsSimplified
from simplified.main_olg_v9_sac_sbx_simplified import OLGEnvV9SACSimplified

class OLGEnvTester:
    """OLGç¯å¢ƒæµ‹è¯•å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•å™¨"""
        print("ğŸ§ª OLGç¯å¢ƒæµ‹è¯•å™¨åˆå§‹åŒ–...")
        
        # åˆå§‹åŒ–å‚æ•°
        self.cS = OLG_V9_Utils.ParameterValues_HuggettStyle()
        leLogGridV, leTrProbM, leProb1V = OLG_V9_Utils.EarningProcess_olgm(self.cS)
        leGridV = np.exp(leLogGridV)
        
        self.paramS_rl = {
            'leLogGridV': leLogGridV,
            'leTrProbM': leTrProbM,
            'leProb1V': leProb1V,
            'leGridV': leGridV,
            'ageEffV_new': self.cS.ageEffV_new
        }
        
        # å›ºå®šå®è§‚å‚æ•°
        self.M_fixed = {
            'R_k_net_factor': 1.03,
            'w_gross': 2.0,
            'TR_total': 0.1,
            'b_payg_avg_retiree': 0.4,
            'tau_l': 0.15,
            'theta_payg_actual': 0.12
        }
        
        print("âœ… å‚æ•°åˆå§‹åŒ–å®Œæˆ")
    
    def create_environment(self, training_mode: bool = False) -> OLGEnvV9SACSimplified:
        """åˆ›å»ºç¯å¢ƒå®ä¾‹"""
        env = OLGEnvV9SACSimplified(
            cS=self.cS,
            paramS_rl=self.paramS_rl,
            M_fixed=self.M_fixed,
            training_mode=training_mode
        )
        return env
    
    def test_basic_functionality(self) -> Dict:
        """æµ‹è¯•åŸºæœ¬åŠŸèƒ½"""
        print("\nğŸ” æµ‹è¯•åŸºæœ¬åŠŸèƒ½...")
        
        env = self.create_environment(training_mode=False)
        
        # é‡ç½®ç¯å¢ƒ
        obs, info = env.reset(seed=42)
        print(f"ğŸ“Š åˆå§‹è§‚æµ‹: {obs}")
        print(f"ğŸ“‹ åˆå§‹ä¿¡æ¯: {info}")
        
        # æ£€æŸ¥è§‚æµ‹ç©ºé—´å’ŒåŠ¨ä½œç©ºé—´
        print(f"ğŸ”¢ è§‚æµ‹ç©ºé—´: {env.observation_space}")
        print(f"ğŸ® åŠ¨ä½œç©ºé—´: {env.action_space}")
        
        # æµ‹è¯•å‡ æ­¥éšæœºåŠ¨ä½œ
        results = {
            'observations': [obs.copy()],
            'actions': [],
            'rewards': [],
            'infos': [],
            'states_raw': []
        }
        
        for step in range(5):
            # ç”ŸæˆéšæœºåŠ¨ä½œ
            action = env.action_space.sample()
            results['actions'].append(action.copy())
            
            # æ‰§è¡ŒåŠ¨ä½œ
            obs_next, reward, terminated, truncated, info = env.step(action)
            
            results['observations'].append(obs_next.copy())
            results['rewards'].append(reward)
            results['infos'].append(info.copy())
            
            # è®°å½•åŸå§‹çŠ¶æ€
            raw_state = {
                'k': env.current_k_val,
                'k_pps': env.current_k_pps_val,
                'age_idx': env.current_age_idx,
                'epsilon_idx': env.current_eps_idx,
                'age': 20 + env.current_age_idx
            }
            results['states_raw'].append(raw_state.copy())
            
            print(f"æ­¥éª¤ {step+1}:")
            print(f"  ğŸ® åŠ¨ä½œ: [PPSç¼´è´¹æ¯”ä¾‹={action[0]:.3f}, éPPSå‚¨è“„æ¯”ä¾‹={action[1]:.3f}]")
            print(f"  ğŸ“Š è§‚æµ‹ (å½“å‰): {obs}")
            print(f"  ğŸ“Š è§‚æµ‹ (ä¸‹æ­¥): {obs_next}")
            print(f"  ğŸ  çŠ¶æ€: k={raw_state['k']:.3f}, k_pps={raw_state['k_pps']:.3f}, age={raw_state['age']}, Îµ_idx={raw_state['epsilon_idx']}")
            print(f"  ğŸ’° å¥–åŠ±: {reward:.6f}")
            print(f"  ğŸ ç»ˆæ­¢: {terminated}, æˆªæ–­: {truncated}")
            if 'consumption' in info:
                print(f"  ğŸ½ï¸  æ¶ˆè´¹: {info['consumption']:.3f}")
            if 'c_pps' in info:
                print(f"  ğŸ’³ PPSç¼´è´¹: {info['c_pps']:.3f}")
            print(f"  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            
            if terminated or truncated:
                print("ğŸ å›åˆç»“æŸ")
                break
            
            obs = obs_next
        
        env.close()
        return results
    
    def test_full_lifecycle(self, n_episodes: int = 3) -> Dict:
        """æµ‹è¯•å®Œæ•´ç”Ÿå‘½å‘¨æœŸ"""
        print(f"\nğŸ”„ æµ‹è¯•å®Œæ•´ç”Ÿå‘½å‘¨æœŸ (n_episodes={n_episodes})...")
        
        all_results = []
        
        for episode in range(n_episodes):
            print(f"\nğŸ“ˆ å›åˆ {episode + 1}/{n_episodes}")
            
            env = self.create_environment(training_mode=False)
            obs, info = env.reset(seed=42 + episode)
            
            episode_data = {
                'episode': episode,
                'states': [],
                'actions': [],
                'rewards': [],
                'consumptions': [],
                'pps_contributions': [],
                'utilities': [],
                'terminated_normally': False
            }
            
            step_count = 0
            total_reward = 0
            
            while True:
                # è®°å½•å½“å‰çŠ¶æ€
                current_state = {
                    'k': env.current_k_val,
                    'k_pps': env.current_k_pps_val,
                    'age_idx': env.current_age_idx,
                    'epsilon_idx': env.current_eps_idx,
                    'age': 20 + env.current_age_idx,
                    'observation': obs.copy()
                }
                episode_data['states'].append(current_state)
                
                # ç”Ÿæˆæ›´åˆç†çš„éšæœºåŠ¨ä½œ
                action = env.action_space.sample()
                # å¹´è½»æ—¶æ›´ä¿å®ˆçš„ç­–ç•¥
                if current_state['age'] < 30:
                    action[0] = np.clip(action[0] * 0.1, 0, 1)  # å¹´è½»æ—¶å¾ˆå°‘PPSç¼´è´¹
                    action[1] = np.clip(action[1] * 0.5, 0, 1)  # é€‚åº¦å‚¨è“„
                else:
                    action[0] = np.clip(action[0] * 0.3, 0, 1)  # ä¸­å¹´æ—¶å¢åŠ PPSç¼´è´¹
                    action[1] = np.clip(action[1] * 0.7, 0, 1)  # ç§¯æå‚¨è“„
                
                episode_data['actions'].append(action.copy())
                
                # æ‰§è¡ŒåŠ¨ä½œ
                obs_next, reward, terminated, truncated, info = env.step(action)
                
                episode_data['rewards'].append(reward)
                total_reward += reward
                
                # ä»infoä¸­æå–è¯¦ç»†ä¿¡æ¯
                if 'consumption' in info:
                    episode_data['consumptions'].append(info['consumption'])
                if 'pps_contribution' in info:
                    episode_data['pps_contributions'].append(info['pps_contribution'])
                if 'utility' in info:
                    episode_data['utilities'].append(info['utility'])
                
                step_count += 1
                
                if step_count % 5 == 0 or step_count <= 3:  # æ˜¾ç¤ºå‰3æ­¥å’Œæ¯5æ­¥
                    print(f"  ğŸ“Š æ­¥éª¤ {step_count}:")
                    print(f"     ğŸ® åŠ¨ä½œ: [PPS={action[0]:.3f}, å‚¨è“„={action[1]:.3f}]")
                    print(f"     ğŸ“Š è§‚æµ‹: {obs}")
                    print(f"     ğŸ  çŠ¶æ€: k={current_state['k']:.3f}, k_pps={current_state['k_pps']:.3f}, age={current_state['age']}, Îµ={current_state['epsilon_idx']}")
                    print(f"     ğŸ’° å¥–åŠ±: {reward:.6f}")
                    if 'consumption' in info:
                        print(f"     ğŸ½ï¸  æ¶ˆè´¹: {info['consumption']:.3f}")
                    if 'c_pps' in info:
                        print(f"     ğŸ’³ PPS: {info['c_pps']:.3f}")
                    print(f"     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
                
                if terminated or truncated:
                    episode_data['terminated_normally'] = terminated
                    print(f"ğŸ å›åˆç»“æŸ: æ­¥éª¤={step_count}, æ€»å¥–åŠ±={total_reward:.4f}, æ­£å¸¸ç»“æŸ={terminated}")
                    break
                
                obs = obs_next
            
            episode_data['total_steps'] = step_count
            episode_data['total_reward'] = total_reward
            all_results.append(episode_data)
            
            env.close()
        
        return all_results
    
    def analyze_results(self, results: List[Dict]) -> Dict:
        """åˆ†ææµ‹è¯•ç»“æœ"""
        print("\nğŸ“Š åˆ†ææµ‹è¯•ç»“æœ...")
        
        analysis = {
            'summary': {},
            'lifecycle_stats': {},
            'validation_checks': {}
        }
        
        # æ±‡æ€»ç»Ÿè®¡
        total_rewards = [ep['total_reward'] for ep in results]
        total_steps = [ep['total_steps'] for ep in results]
        
        analysis['summary'] = {
            'n_episodes': len(results),
            'avg_total_reward': np.mean(total_rewards),
            'std_total_reward': np.std(total_rewards),
            'avg_steps': np.mean(total_steps),
            'std_steps': np.std(total_steps),
            'all_terminated_normally': all(ep['terminated_normally'] for ep in results)
        }
        
        # ç”Ÿå‘½å‘¨æœŸç»Ÿè®¡ï¼ˆä½¿ç”¨ç¬¬ä¸€ä¸ªå›åˆï¼‰
        if results:
            first_episode = results[0]
            
            ages = [state['age'] for state in first_episode['states']]
            k_path = [state['k'] for state in first_episode['states']]
            k_pps_path = [state['k_pps'] for state in first_episode['states']]
            consumptions = first_episode['consumptions']
            rewards = first_episode['rewards']
            
            analysis['lifecycle_stats'] = {
                'age_range': (min(ages), max(ages)),
                'k_range': (min(k_path), max(k_path)),
                'k_pps_range': (min(k_pps_path), max(k_pps_path)),
                'consumption_range': (min(consumptions), max(consumptions)) if consumptions else (0, 0),
                'reward_range': (min(rewards), max(rewards)),
                'avg_consumption': np.mean(consumptions) if consumptions else 0,
                'avg_reward': np.mean(rewards)
            }
        
        # éªŒè¯æ£€æŸ¥ï¼ˆç®€åŒ–ç‰ˆï¼š16ä¸ªå¹´é¾„ç»„è€Œä¸æ˜¯79ä¸ªå¹´åº¦å¹´é¾„ï¼‰
        expected_steps = 16  # ç®€åŒ–ç‰ˆä½¿ç”¨å¹´é¾„ç»„
        validation_checks = {
            'all_episodes_completed': all(ep['total_steps'] >= expected_steps for ep in results),
            'positive_consumption': True,
            'reasonable_rewards': True,
            'state_transitions_valid': True
        }
        
        # æ£€æŸ¥æ¶ˆè´¹æ˜¯å¦ä¸ºæ­£
        for ep in results:
            if ep['consumptions'] and any(c <= 0 for c in ep['consumptions']):
                validation_checks['positive_consumption'] = False
                break
        
        # æ£€æŸ¥å¥–åŠ±æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…
        for ep in results:
            if any(abs(r) > 100 for r in ep['rewards']):  # è¿‡å¤§çš„å¥–åŠ±å¯èƒ½è¡¨ç¤ºæœ‰é—®é¢˜
                validation_checks['reasonable_rewards'] = False
                break
        
        analysis['validation_checks'] = validation_checks
        
        return analysis
    
    def plot_lifecycle_paths(self, results: List[Dict], save_path: str = None):
        """ç»˜åˆ¶ç”Ÿå‘½å‘¨æœŸè·¯å¾„"""
        print("\nğŸ“ˆ ç»˜åˆ¶ç”Ÿå‘½å‘¨æœŸè·¯å¾„...")
        
        if not results:
            print("âŒ æ²¡æœ‰ç»“æœå¯ç»˜åˆ¶")
            return
        
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        fig.suptitle('OLGç¯å¢ƒæµ‹è¯•ï¼šéšæœºç­–ç•¥ç”Ÿå‘½å‘¨æœŸè·¯å¾„', fontsize=14)
        
        colors = ['blue', 'red', 'green', 'orange', 'purple']
        
        for i, episode_data in enumerate(results[:3]):  # æœ€å¤šæ˜¾ç¤º3ä¸ªå›åˆ
            color = colors[i % len(colors)]
            label = f'å›åˆ {i+1}'
            
            ages = [state['age'] for state in episode_data['states']]
            k_path = [state['k'] for state in episode_data['states']]
            k_pps_path = [state['k_pps'] for state in episode_data['states']]
            consumptions = episode_data['consumptions']
            rewards = episode_data['rewards']
            pps_contributions = episode_data['pps_contributions']
            
            # 1. èµ„äº§è·¯å¾„
            axes[0, 0].plot(ages, k_path, color=color, label=label, alpha=0.7)
            axes[0, 0].set_xlabel('å¹´é¾„')
            axes[0, 0].set_ylabel('æ™®é€šèµ„äº§ (k)')
            axes[0, 0].set_title('æ™®é€šèµ„äº§è·¯å¾„')
            axes[0, 0].grid(True, alpha=0.3)
            axes[0, 0].legend()
            
            # 2. PPSèµ„äº§è·¯å¾„
            axes[0, 1].plot(ages, k_pps_path, color=color, label=label, alpha=0.7)
            axes[0, 1].set_xlabel('å¹´é¾„')
            axes[0, 1].set_ylabel('PPSèµ„äº§ (k_pps)')
            axes[0, 1].set_title('PPSèµ„äº§è·¯å¾„')
            axes[0, 1].grid(True, alpha=0.3)
            axes[0, 1].legend()
            
            # 3. æ¶ˆè´¹è·¯å¾„
            if consumptions:
                axes[0, 2].plot(ages[:len(consumptions)], consumptions, color=color, label=label, alpha=0.7)
            axes[0, 2].set_xlabel('å¹´é¾„')
            axes[0, 2].set_ylabel('æ¶ˆè´¹ (c)')
            axes[0, 2].set_title('æ¶ˆè´¹è·¯å¾„')
            axes[0, 2].grid(True, alpha=0.3)
            axes[0, 2].legend()
            
            # 4. å¥–åŠ±è·¯å¾„
            axes[1, 0].plot(ages[:len(rewards)], rewards, color=color, label=label, alpha=0.7)
            axes[1, 0].set_xlabel('å¹´é¾„')
            axes[1, 0].set_ylabel('å³æ—¶å¥–åŠ±')
            axes[1, 0].set_title('å¥–åŠ±è·¯å¾„')
            axes[1, 0].grid(True, alpha=0.3)
            axes[1, 0].legend()
            
            # 5. PPSç¼´è´¹è·¯å¾„
            if pps_contributions:
                axes[1, 1].plot(ages[:len(pps_contributions)], pps_contributions, color=color, label=label, alpha=0.7)
            axes[1, 1].set_xlabel('å¹´é¾„')
            axes[1, 1].set_ylabel('PPSç¼´è´¹')
            axes[1, 1].set_title('PPSç¼´è´¹è·¯å¾„')
            axes[1, 1].grid(True, alpha=0.3)
            axes[1, 1].legend()
            
            # 6. æ€»èµ„äº§è·¯å¾„
            total_assets = [k + k_pps for k, k_pps in zip(k_path, k_pps_path)]
            axes[1, 2].plot(ages, total_assets, color=color, label=label, alpha=0.7)
            axes[1, 2].set_xlabel('å¹´é¾„')
            axes[1, 2].set_ylabel('æ€»èµ„äº§ (k + k_pps)')
            axes[1, 2].set_title('æ€»èµ„äº§è·¯å¾„')
            axes[1, 2].grid(True, alpha=0.3)
            axes[1, 2].legend()
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ“ˆ å›¾è¡¨å·²ä¿å­˜åˆ°: {save_path}")
        
        plt.show()
    
    def print_analysis_report(self, analysis: Dict):
        """æ‰“å°åˆ†ææŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“‹ OLGç¯å¢ƒæµ‹è¯•åˆ†ææŠ¥å‘Š")
        print("="*60)
        
        # æ±‡æ€»ç»Ÿè®¡
        summary = analysis['summary']
        print(f"\nğŸ”¢ æ±‡æ€»ç»Ÿè®¡:")
        print(f"  æµ‹è¯•å›åˆæ•°: {summary['n_episodes']}")
        print(f"  å¹³å‡æ€»å¥–åŠ±: {summary['avg_total_reward']:.4f} Â± {summary['std_total_reward']:.4f}")
        print(f"  å¹³å‡æ­¥æ•°: {summary['avg_steps']:.1f} Â± {summary['std_steps']:.1f}")
        print(f"  æ‰€æœ‰å›åˆæ­£å¸¸ç»“æŸ: {'âœ…' if summary['all_terminated_normally'] else 'âŒ'}")
        
        # ç”Ÿå‘½å‘¨æœŸç»Ÿè®¡
        if 'lifecycle_stats' in analysis:
            lifecycle = analysis['lifecycle_stats']
            print(f"\nğŸ“Š ç”Ÿå‘½å‘¨æœŸç»Ÿè®¡:")
            print(f"  å¹´é¾„èŒƒå›´: {lifecycle['age_range'][0]} - {lifecycle['age_range'][1]} å²")
            print(f"  æ™®é€šèµ„äº§èŒƒå›´: {lifecycle['k_range'][0]:.3f} - {lifecycle['k_range'][1]:.3f}")
            print(f"  PPSèµ„äº§èŒƒå›´: {lifecycle['k_pps_range'][0]:.3f} - {lifecycle['k_pps_range'][1]:.3f}")
            print(f"  æ¶ˆè´¹èŒƒå›´: {lifecycle['consumption_range'][0]:.3f} - {lifecycle['consumption_range'][1]:.3f}")
            print(f"  å¥–åŠ±èŒƒå›´: {lifecycle['reward_range'][0]:.6f} - {lifecycle['reward_range'][1]:.6f}")
            print(f"  å¹³å‡æ¶ˆè´¹: {lifecycle['avg_consumption']:.3f}")
            print(f"  å¹³å‡å¥–åŠ±: {lifecycle['avg_reward']:.6f}")
        
        # éªŒè¯æ£€æŸ¥
        validation = analysis['validation_checks']
        print(f"\nâœ… éªŒè¯æ£€æŸ¥:")
        print(f"  æ‰€æœ‰å›åˆå®Œæˆ (â‰¥16æ­¥): {'âœ…' if validation['all_episodes_completed'] else 'âŒ'}")
        print(f"  æ¶ˆè´¹å§‹ç»ˆä¸ºæ­£: {'âœ…' if validation['positive_consumption'] else 'âŒ'}")
        print(f"  å¥–åŠ±åœ¨åˆç†èŒƒå›´: {'âœ…' if validation['reasonable_rewards'] else 'âŒ'}")
        print(f"  çŠ¶æ€è½¬ç§»æœ‰æ•ˆ: {'âœ…' if validation['state_transitions_valid'] else 'âŒ'}")
        
        # æ€»ä½“è¯„ä¼°
        all_checks_passed = all(validation.values())
        print(f"\nğŸ¯ æ€»ä½“è¯„ä¼°: {'âœ… ç¯å¢ƒåŠŸèƒ½æ­£å¸¸' if all_checks_passed else 'âŒ å‘ç°æ½œåœ¨é—®é¢˜'}")
        
        print("="*60)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª OLGç¯å¢ƒç®€åŒ–ç‰ˆæµ‹è¯•")
    print("ğŸ¯ ä½¿ç”¨éšæœºå†³ç­–æµ‹è¯•ç¯å¢ƒåŠŸèƒ½")
    print("="*60)
    
    # åˆ›å»ºæµ‹è¯•å™¨
    tester = OLGEnvTester()
    
    # 1. åŸºæœ¬åŠŸèƒ½æµ‹è¯•
    print("\n1ï¸âƒ£ åŸºæœ¬åŠŸèƒ½æµ‹è¯•...")
    basic_results = tester.test_basic_functionality()
    
    # 2. å®Œæ•´ç”Ÿå‘½å‘¨æœŸæµ‹è¯•
    print("\n2ï¸âƒ£ å®Œæ•´ç”Ÿå‘½å‘¨æœŸæµ‹è¯•...")
    lifecycle_results = tester.test_full_lifecycle(n_episodes=3)
    
    # 3. ç»“æœåˆ†æ
    print("\n3ï¸âƒ£ ç»“æœåˆ†æ...")
    analysis = tester.analyze_results(lifecycle_results)
    
    # 4. ç»˜åˆ¶è·¯å¾„
    print("\n4ï¸âƒ£ ç»˜åˆ¶ç”Ÿå‘½å‘¨æœŸè·¯å¾„...")
    save_path = './simplified/olg_env_test_paths.png'
    tester.plot_lifecycle_paths(lifecycle_results, save_path=save_path)
    
    # 5. æ‰“å°æŠ¥å‘Š
    print("\n5ï¸âƒ£ ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
    tester.print_analysis_report(analysis)
    
    # 6. ä¿å­˜è¯¦ç»†ç»“æœ
    import pickle
    with open('./simplified/olg_env_test_results.pkl', 'wb') as f:
        pickle.dump({
            'basic_results': basic_results,
            'lifecycle_results': lifecycle_results,
            'analysis': analysis,
            'test_timestamp': time.time()
        }, f)
    
    print("\nğŸ’¾ è¯¦ç»†æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: ./simplified/olg_env_test_results.pkl")
    
    return analysis

if __name__ == "__main__":
    results = main() 